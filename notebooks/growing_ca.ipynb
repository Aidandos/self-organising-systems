{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "28S76DVlfCMZ"
      },
      "source": [
        "# Growing Neural Cellular Automata\n",
        "\n",
        "This notebook contains code to reproduce experiments and figures for the \"Growing Neural Cellular Automata\" article [TODO link].\n",
        "\n",
        "Copyright 2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "i5wi_r4gyzFr"
      },
      "outputs": [],
      "source": [
        "#@title imports and notebook utils\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pylab as pl\n",
        "import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "import tqdm\n",
        "\n",
        "import os\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "import moviepy.editor as mvp\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "clear_output()\n",
        "\n",
        "def np2pil(a):\n",
        "  if a.dtype in [np.float32, np.float64]:\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=95)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def im2url(a, fmt='jpeg'):\n",
        "  encoded = imencode(a, fmt)\n",
        "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
        "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
        "\n",
        "def imshow(a, fmt='jpeg'):\n",
        "  display(Image(data=imencode(a, fmt)))\n",
        "\n",
        "def tile2d(a, w=None):\n",
        "  a = np.asarray(a)\n",
        "  if w is None:\n",
        "    w = int(np.ceil(np.sqrt(len(a))))\n",
        "  th, tw = a.shape[1:3]\n",
        "  pad = (w-len(a))%w\n",
        "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
        "  h = len(a)//w\n",
        "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
        "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
        "  return a\n",
        "\n",
        "def zoom(img, scale=4):\n",
        "  img = np.repeat(img, scale, 0)\n",
        "  img = np.repeat(img, scale, 1)\n",
        "  return img\n",
        "\n",
        "class VideoWriter:\n",
        "  def __init__(self, filename, fps=30.0, **kw):\n",
        "    self.writer = None\n",
        "    self.params = dict(filename=filename, fps=fps, **kw)\n",
        "\n",
        "  def add(self, img):\n",
        "    img = np.asarray(img)\n",
        "    if self.writer is None:\n",
        "      h, w = img.shape[:2]\n",
        "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
        "    if img.dtype in [np.float32, np.float64]:\n",
        "      img = np.uint8(img.clip(0, 1)*255)\n",
        "    if len(img.shape) == 2:\n",
        "      img = np.repeat(img[..., None], 3, -1)\n",
        "    self.writer.write_frame(img)\n",
        "\n",
        "  def close(self):\n",
        "    if self.writer:\n",
        "      self.writer.close()\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "\n",
        "  def __exit__(self, *kw):\n",
        "    self.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O-ssztk0fwi5"
      },
      "source": [
        "## Cellular Automata parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zR6I1JONmWBb"
      },
      "outputs": [],
      "source": [
        "CHANNEL_N = 16        # Number of CA state channels\n",
        "TARGET_PADDING = 16   # Number of pixels used to pad the target image border\n",
        "TARGET_SIZE = 40\n",
        "BATCH_SIZE = 8\n",
        "POOL_SIZE = 1024\n",
        "CELL_FIRE_RATE = 0.5\n",
        "\n",
        "EXPERIMENT_N = 2  # experiment number: [0, 1, 2]\n",
        "USE_PATTERN_POOL = [0, 1, 1][EXPERIMENT_N]\n",
        "DAMAGE_N = [0, 0, 3][EXPERIMENT_N]  # Number of patterns to damage in a batch\n",
        "\n",
        "TARGET_EMOJI = '🦎'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "lCbPFbI_zosW"
      },
      "outputs": [],
      "source": [
        "#@title CA Model and utils\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "def load_image(url, max_size=TARGET_SIZE):\n",
        "  r = requests.get(url)\n",
        "  img = PIL.Image.open(io.BytesIO(r.content))\n",
        "  img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
        "  img = np.float32(img)/255.0\n",
        "  # premultiply RGB by Alpha\n",
        "  img[..., :3] *= img[..., 3:]\n",
        "  return img\n",
        "\n",
        "def load_emoji(emoji):\n",
        "  code = hex(ord(emoji))[2:].lower()\n",
        "  url = 'https://github.com/googlefonts/noto-emoji/raw/master/png/128/emoji_u%s.png'%code\n",
        "  return load_image(url)\n",
        "\n",
        "\n",
        "def to_rgba(x):\n",
        "  return x[..., :4]\n",
        "\n",
        "def to_alpha(x):\n",
        "  return tf.clip_by_value(x[..., 3:4], 0.0, 1.0)\n",
        "\n",
        "def to_rgb(x):\n",
        "  # assume rgb premultiplied by alpha\n",
        "  rgb, a = x[..., :3], to_alpha(x)\n",
        "  return 1.0-a+rgb\n",
        "\n",
        "def get_living_mask(x):\n",
        "  return tf.nn.max_pool2d(to_alpha(x), 3, [1, 1, 1, 1], 'SAME') \u003e 0.1\n",
        "\n",
        "def make_seed(size, n=1):\n",
        "  x = np.zeros([n, size, size, CHANNEL_N], np.float32)\n",
        "  x[:, size//2, size//2, 3:] = 1.0\n",
        "  return x\n",
        "\n",
        "\n",
        "class CAModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE):\n",
        "    super().__init__()\n",
        "    self.channel_n = channel_n\n",
        "    self.fire_rate = fire_rate\n",
        "\n",
        "    self.dmodel = tf.keras.Sequential([\n",
        "          Conv2D(128, 1, activation=tf.nn.relu),\n",
        "          Conv2D(self.channel_n, 1, activation=None,\n",
        "              kernel_initializer=tf.zeros_initializer),\n",
        "    ])\n",
        "\n",
        "    self(tf.zeros([1, 3, 3, channel_n]))  # dummpy call to build the model\n",
        "\n",
        "  @tf.function\n",
        "  def perceive(self, x, angle=0.0):\n",
        "    identify = np.float32([0, 1, 0])\n",
        "    identify = np.outer(identify, identify)\n",
        "    dx = np.outer([1, 2, 1], [-1, 0, 1]) / 8.0  # Sobel filter\n",
        "    dy = dx.T\n",
        "    c, s = tf.cos(angle), tf.sin(angle)\n",
        "    kernel = tf.stack([identify, c*dx-s*dy, s*dx+c*dy], -1)[:, :, None, :]\n",
        "    kernel = tf.repeat(kernel, self.channel_n, 2)\n",
        "    y = tf.nn.depthwise_conv2d(x, kernel, [1, 1, 1, 1], 'SAME')\n",
        "    return y\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x, fire_rate=None, angle=0.0, step_size=1.0):\n",
        "    pre_life_mask = get_living_mask(x)\n",
        "\n",
        "    y = self.perceive(x, angle)\n",
        "    dx = self.dmodel(y)*step_size\n",
        "    if fire_rate is None:\n",
        "      fire_rate = self.fire_rate\n",
        "    update_mask = tf.random.uniform(tf.shape(x[:, :, :, :1])) \u003c= fire_rate\n",
        "    x += dx * tf.cast(update_mask, tf.float32)\n",
        "\n",
        "    post_life_mask = get_living_mask(x)\n",
        "    life_mask = pre_life_mask \u0026 post_life_mask\n",
        "    return x * tf.cast(life_mask, tf.float32)\n",
        "\n",
        "\n",
        "CAModel().dmodel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xDX5HL7VLd0z"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "IeWf6HeTe8kM"
      },
      "outputs": [],
      "source": [
        "#@title Train utils (SamplePool, model export, damage)\n",
        "from google.protobuf.json_format import MessageToDict\n",
        "from tensorflow.python.framework import convert_to_constants\n",
        "\n",
        "class SamplePool:\n",
        "  def __init__(self, *, _parent=None, _parent_idx=None, **slots):\n",
        "    self._parent = _parent\n",
        "    self._parent_idx = _parent_idx\n",
        "    self._slot_names = slots.keys()\n",
        "    self._size = None\n",
        "    for k, v in slots.items():\n",
        "      if self._size is None:\n",
        "        self._size = len(v)\n",
        "      assert self._size == len(v)\n",
        "      setattr(self, k, np.asarray(v))\n",
        "\n",
        "  def sample(self, n):\n",
        "    idx = np.random.choice(self._size, n, False)\n",
        "    batch = {k: getattr(self, k)[idx] for k in self._slot_names}\n",
        "    batch = SamplePool(**batch, _parent=self, _parent_idx=idx)\n",
        "    return batch\n",
        "\n",
        "  def commit(self):\n",
        "    for k in self._slot_names:\n",
        "      getattr(self._parent, k)[self._parent_idx] = getattr(self, k)\n",
        "\n",
        "@tf.function\n",
        "def make_circle_masks(n, h, w):\n",
        "  x = tf.linspace(-1.0, 1.0, w)[None, None, :]\n",
        "  y = tf.linspace(-1.0, 1.0, h)[None, :, None]\n",
        "  center = tf.random.uniform([2, n, 1, 1], -0.5, 0.5)\n",
        "  r = tf.random.uniform([n, 1, 1], 0.1, 0.4)\n",
        "  x, y = (x-center[0])/r, (y-center[1])/r\n",
        "  mask = tf.cast(x*x+y*y \u003c 1.0, tf.float32)\n",
        "  return mask\n",
        "\n",
        "def export_model(ca, base_fn):\n",
        "  ca.save_weights(base_fn)\n",
        "\n",
        "  cf = ca.call.get_concrete_function(\n",
        "      x=tf.TensorSpec([None, None, None, CHANNEL_N]),\n",
        "      fire_rate=tf.constant(0.5),\n",
        "      angle=tf.constant(0.0),\n",
        "      step_size=tf.constant(1.0))\n",
        "  cf = convert_to_constants.convert_variables_to_constants_v2(cf)\n",
        "  graph_def = cf.graph.as_graph_def()\n",
        "  graph_json = MessageToDict(graph_def)\n",
        "  graph_json['versions'] = dict(producer='1.14', minConsumer='1.14')\n",
        "  model_json = {\n",
        "      'format': 'graph-model',\n",
        "      'modelTopology': graph_json,\n",
        "      'weightsManifest': [],\n",
        "  }\n",
        "  with open(base_fn+'.json', 'w') as f:\n",
        "    json.dump(model_json, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "zKlA50h0jlvl"
      },
      "outputs": [],
      "source": [
        "#@title Target image { vertical-output: true}\n",
        "#url = 'https://storage.googleapis.com/deepdream/planaria2_48.png'\n",
        "#target_img = load_image(url, 48)\n",
        "\n",
        "target_img = load_emoji(TARGET_EMOJI)\n",
        "imshow(zoom(to_rgb(target_img), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "both",
        "colab": {},
        "colab_type": "code",
        "id": "ak5rBmbxmHV7"
      },
      "outputs": [],
      "source": [
        "# Init training\n",
        "\n",
        "p = TARGET_PADDING\n",
        "pad_target = tf.pad(target_img, [(p, p), (p, p), (0, 0)])\n",
        "h, w = pad_target.shape[:2]\n",
        "seed = np.zeros([h, w, CHANNEL_N], np.float32)\n",
        "seed[h//2, w//2, 3:] = 1.0\n",
        "\n",
        "def loss_f(x):\n",
        "  return tf.reduce_mean(tf.square(to_rgba(x)-pad_target), [-2, -3, -1])\n",
        "\n",
        "ca = CAModel()\n",
        "\n",
        "loss_log = []\n",
        "\n",
        "lr = 2e-3\n",
        "lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    [2000], [lr, lr*0.1])\n",
        "trainer = tf.keras.optimizers.Adam(lr_sched)\n",
        "\n",
        "loss0 = loss_f(seed).numpy()\n",
        "pool = SamplePool(x=np.repeat(seed[None, ...], POOL_SIZE, 0))\n",
        "\n",
        "!mkdir -p train_log \u0026\u0026 rm -f train_log/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QzP_vDchq0d9"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "\n",
        "@tf.function\n",
        "def train_step(x):\n",
        "  iter_n = tf.random.uniform([], 64, 96, tf.int32)\n",
        "  with tf.GradientTape() as g:\n",
        "    for i in tf.range(iter_n):\n",
        "      x = ca(x)\n",
        "    loss = tf.reduce_mean(loss_f(x))\n",
        "  grads = g.gradient(loss, ca.weights)\n",
        "  grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
        "  trainer.apply_gradients(zip(grads, ca.weights))\n",
        "  return x, loss\n",
        "\n",
        "for i in range(4000+1):\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch = pool.sample(BATCH_SIZE)\n",
        "    x0 = batch.x\n",
        "    loss_rank = loss_f(x0).numpy().argsort()[::-1]\n",
        "    x0 = x0[loss_rank]\n",
        "    x0[:1] = seed\n",
        "    if DAMAGE_N:\n",
        "      damage = 1.0-make_circle_masks(DAMAGE_N, h, w).numpy()[..., None]\n",
        "      x0[-DAMAGE_N:] *= damage\n",
        "  else:\n",
        "    x0 = np.repeat(seed[None, ...], BATCH_SIZE, 0)\n",
        "\n",
        "  x, loss = train_step(x0)\n",
        "\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch.x[:] = x\n",
        "    batch.commit()\n",
        "\n",
        "  step_i = len(loss_log)\n",
        "  loss_log.append(loss.numpy())\n",
        "  if step_i%100 == 0:\n",
        "    vis0 = np.hstack(to_rgb(x0).numpy())\n",
        "    vis1 = np.hstack(to_rgb(x).numpy())\n",
        "    vis = np.vstack([vis0, vis1])\n",
        "    imwrite('train_log/%04d.jpg'%step_i, vis)\n",
        "    export_model(ca, 'train_log/%04d'%step_i)\n",
        "    clear_output()\n",
        "    print('batch (before/after):')\n",
        "    imshow(vis)\n",
        "    pl.figure(figsize=(10, 4))\n",
        "    pl.title('Loss history (log10)')\n",
        "    pl.plot(np.log10(loss_log), '.', alpha=0.1)\n",
        "    pl.show()\n",
        "  print('\\r step: %d, log10(loss): %.3f'%(len(loss_log), np.log10(loss)), end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QAscSKkRaFwp"
      },
      "source": [
        "# Figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "nqvkfl9W4ODI"
      },
      "outputs": [],
      "source": [
        "#@title training progress (checkpoints)\n",
        "\n",
        "models = []\n",
        "for i in [100, 500, 1000, 4000]:\n",
        "  ca = CAModel()\n",
        "  ca.load_weights('train_log/%04d'%i)\n",
        "  models.append(ca)\n",
        "\n",
        "out_fn = 'train_steps_damage_%d.mp4'%DAMAGE_N\n",
        "x = np.zeros([len(models), 72, 72, CHANNEL_N], np.float32)\n",
        "x[..., 36, 36, 3:] = 1.0\n",
        "with VideoWriter(out_fn) as vid:\n",
        "  for i in tqdm.trange(500):\n",
        "    vis = np.hstack(to_rgb(x))\n",
        "    vid.add(zoom(vis, 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "mvp.ipython_display(out_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "QeXZKb5v2gxj"
      },
      "outputs": [],
      "source": [
        "#@title training progress (batches)\n",
        "frames = sorted(glob.glob('train_log/*.jpg'))\n",
        "mvp.ImageSequenceClip(frames, fps=10.0).write_videofile('batches.mp4')\n",
        "mvp.ipython_display('batches.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u57S5tCxhcNp"
      },
      "source": [
        "## pretrained models\n",
        "\n",
        "Please run the cell below to download pretrained models that are used to generate the subsequent figures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wiGl7S0E6-OA"
      },
      "outputs": [],
      "source": [
        "!wget -N https://storage.googleapis.com/deepdream/models.zip\n",
        "!unzip -oq models.zip\n",
        "\n",
        "EMOJI = '😀💥👁🦎🐠🦋🐞🕸🥨🎄'\n",
        "\n",
        "def get_model(emoji='🦋', fire_rate=0.5, use_pool=1, damage_n=3, run=0,\n",
        "              prefix='models/', output='model'):\n",
        "  path = prefix\n",
        "  assert fire_rate in [0.5, 1.0]\n",
        "  if fire_rate==0.5:\n",
        "    path += 'use_sample_pool_%d damage_n_%d '%(use_pool, damage_n)\n",
        "  elif fire_rate==1.0:\n",
        "    path += 'fire_rate_1.0 '\n",
        "  code = hex(ord(emoji))[2:].upper()\n",
        "  path += 'target_emoji_%s run_index_%d/08000'%(code, run)\n",
        "  assert output in ['model', 'json']\n",
        "  if output == 'model':\n",
        "    ca = CAModel(channel_n=16, fire_rate=fire_rate)\n",
        "    ca.load_weights(path)\n",
        "    return ca\n",
        "  elif output == 'json':\n",
        "    return open(path+'.json', 'r').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "l6941v0zHIkA"
      },
      "outputs": [],
      "source": [
        "#@title Teaser\n",
        "models = [get_model(emoji, run=1) for emoji in EMOJI]\n",
        "\n",
        "for m in models:\n",
        "  for w in m.weights:\n",
        "    w1 = w.numpy()\n",
        "    s = 2.0*np.abs(w1).max()\n",
        "    print(s)\n",
        "    w1 = w1/s+0.5\n",
        "    w1 = np.round(w1*255)/255\n",
        "    w1 = (w1-0.5)*s\n",
        "    #w.assign(w1)\n",
        "\n",
        "with VideoWriter('teaser.mp4') as vid:\n",
        "  x = np.zeros([len(EMOJI), 64, 64, CHANNEL_N], np.float32)\n",
        "  # grow\n",
        "  for i in tqdm.trange(200):\n",
        "    k = i//20\n",
        "    if i%20==0 and k\u003clen(EMOJI):\n",
        "      x[k, 32, 32, 3:] = 1.0\n",
        "    vid.add(zoom(tile2d(to_rgb(x), 5), 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # damage\n",
        "  mask = PIL.Image.new('L', (64*5, 64*2))\n",
        "  draw = PIL.ImageDraw.Draw(mask)\n",
        "  for i in tqdm.trange(400):\n",
        "    cx, r = i*3-20, 6\n",
        "    y1, y2 = 32+np.sin(i/5+np.pi)*8, 32+64+np.sin(i/5)*8\n",
        "    draw.rectangle((0, 0, 64*5, 64*2), fill=0)\n",
        "    draw.ellipse((cx-r, y1-r, cx+r, y1+r), fill=255)\n",
        "    draw.ellipse((cx-r, y2-r, cx+r, y2+r), fill=255)\n",
        "    x *= 1.0-(np.float32(mask).reshape(2, 64, 5, 64)\n",
        "        .transpose([0, 2, 1, 3]).reshape(10, 64, 64, 1))/255.0\n",
        "    if i\u003c200 or i%2 == 0:\n",
        "      vid.add(zoom(tile2d(to_rgb(x), 5), 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # fade out\n",
        "  last = zoom(tile2d(to_rgb(x), 5), 2)\n",
        "  for t in np.linspace(0, 1, 30):\n",
        "    vid.add(last*(1.0-t)+t)\n",
        "\n",
        "mvp.ipython_display('teaser.mp4', loop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "4O4tzfe-GRJ7"
      },
      "outputs": [],
      "source": [
        "#@title Unstable patterns\n",
        "import PIL.ImageFont\n",
        "from matplotlib import font_manager as fm\n",
        "font_fn = fm.findfont(fm.FontProperties())\n",
        "font = PIL.ImageFont.truetype(font_fn, 20)\n",
        "\n",
        "models = [get_model(ch, use_pool=0, damage_n=0) for ch in EMOJI]\n",
        "fn = 'unstable.mp4'\n",
        "with VideoWriter(fn) as vid:\n",
        "  x = np.zeros([len(EMOJI), 64, 64, CHANNEL_N], np.float32)\n",
        "  x[:, 32, 32, 3:] = 1.0\n",
        "  # grow\n",
        "  for i in tqdm.trange(1000):\n",
        "    if i\u003c200 or i%5 == 0:\n",
        "      vis = zoom(tile2d(to_rgb(x), 5), 2).clip(0, 1)\n",
        "      vis_extended = np.concatenate((vis, np.ones((50, vis.shape[1], 3))), axis=0) \n",
        "      im = np.uint8(vis_extended*255)\n",
        "      im = PIL.Image.fromarray(im)\n",
        "      draw = PIL.ImageDraw.Draw(im)\n",
        "      draw.text((vis.shape[1]//2 - 42, vis.shape[0]), 'step %03d'%i, fill=0, font=font)\n",
        "      vid.add(np.uint8(im))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # fade out\n",
        "  for t in np.linspace(0, 1, 30):\n",
        "    vid.add(vis_extended*(1.0-t)+t)\n",
        "\n",
        "mvp.ipython_display(fn, loop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "both",
        "colab": {},
        "colab_type": "code",
        "id": "1CVR9MeYnjuY"
      },
      "outputs": [],
      "source": [
        "#@title Rotation\n",
        "row_size = 6\n",
        "models_of_interest = [\"🦋\",\"🦎\",\"🐠\",\"😀\"]\n",
        "rotate_by = 15\n",
        "num_images = 360 // 15\n",
        "radiant_change = rotate_by / 180 * np.pi\n",
        "imgs = []\n",
        "\n",
        "for i in np.arange(num_images):\n",
        "  ang = i * radiant_change\n",
        "  if i % row_size == 0:\n",
        "    ca = get_model(models_of_interest[i // row_size])\n",
        "\n",
        "  x = np.zeros([1, 56, 56, CHANNEL_N], np.float32)\n",
        "  x[:, 28, 28, 3:] = 1.0\n",
        "  for i in range(500):\n",
        "    ang = tf.constant(ang, tf.float32)\n",
        "    x = ca(x, angle=ang)\n",
        "  imgs.append(to_rgb(x)[0])\n",
        "# Assumes the result is a multiple of row_size\n",
        "assert len(imgs) % row_size == 0\n",
        "imgs = zip(*(iter(imgs),) * row_size)\n",
        "\n",
        "imgs_arr = np.concatenate([np.hstack(im_row) for im_row in imgs])\n",
        "vis = zoom(imgs_arr, 2)\n",
        "\n",
        "imshow(vis)\n",
        "imwrite('rotation.png', vis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IoJI_u_oYf5n"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('rotation.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "zmXgjVdw0FwY"
      },
      "outputs": [],
      "source": [
        "#@title Internal states\n",
        "ca = get_model()\n",
        "\n",
        "x = np.zeros([1, 48, 48, CHANNEL_N], np.float32)\n",
        "x[:, 24, 24, 3:] = 1.0\n",
        "for i in range(400):\n",
        "  x = ca(x)\n",
        "vis = x.numpy()[0].transpose([2, 0, 1])\n",
        "vis = tile2d(vis, CHANNEL_N//2)\n",
        "vis = zoom(pl.cm.RdBu_r(vis*0.4+0.5), 2)\n",
        "imshow(vis)\n",
        "imwrite('states.png', vis) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "S5JRLGxX1dnX"
      },
      "outputs": [],
      "source": [
        "#@title regeneration (trained without damage)\n",
        "models = [get_model(ch, damage_n=0) for ch in '😀🦋🦎']\n",
        "with VideoWriter('regen1.mp4') as vid:\n",
        "  x = np.zeros([len(models), 5, 56, 56, CHANNEL_N], np.float32)\n",
        "  cx, cy = 28, 28\n",
        "  x[:, :, cy, cx, 3:] = 1.0\n",
        "  for i in tqdm.trange(2000):\n",
        "    if i == 200:\n",
        "      x[:, 0, cy:] = x[:, 1, :cy] = 0\n",
        "      x[:, 2, :, cx:] = x[:, 3, :, :cx] = 0\n",
        "      x[:, 4, cy-8:cy+8, cx-8:cx+8] = 0\n",
        "    vis = to_rgb(x)\n",
        "    vis = np.vstack([np.hstack(row) for row in vis])\n",
        "    vis = zoom(vis, 2)\n",
        "    if (i \u003c 400 and i%2==0) or i%8 == 0:\n",
        "      vid.add(vis)\n",
        "    if i == 200:\n",
        "      for _ in range(29):\n",
        "        vid.add(vis)\n",
        "    for ca, row in zip(models, x):\n",
        "      row[:] = ca(row)\n",
        "\n",
        "mvp.ipython_display('regen1.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "TDzJM69u4_8p"
      },
      "outputs": [],
      "source": [
        "#@title regeneration (trained with damage)\n",
        "models = [get_model(ch, damage_n=3) for ch in '😀🦋🦎']\n",
        "with VideoWriter('regen2.mp4') as vid:\n",
        "  x = np.zeros([len(models), 5, 56, 56, CHANNEL_N], np.float32)\n",
        "  cx, cy = 28, 28\n",
        "  x[:, :, cy, cx, 3:] = 1.0\n",
        "  for i in tqdm.trange(2000):\n",
        "    if i == 200:\n",
        "      x[:, 0, cy:] = x[:, 1, :cy] = 0\n",
        "      x[:, 2, :, cx:] = x[:, 3, :, :cx] = 0\n",
        "      x[:, 4, cy-8:cy+8, cx-8:cx+8] = 0\n",
        "    vis = to_rgb(x)\n",
        "    vis = np.vstack([np.hstack(row) for row in vis])\n",
        "    vis = zoom(vis, 2)\n",
        "    if (i \u003c 400 and i%2==0) or i%8 == 0:\n",
        "      vid.add(vis)\n",
        "    if i == 200:\n",
        "      for _ in range(29):\n",
        "        vid.add(vis)\n",
        "    for ca, row in zip(models, x):\n",
        "      row[:] = ca(row)\n",
        "\n",
        "mvp.ipython_display('regen2.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "Csx8vxMcderu"
      },
      "outputs": [],
      "source": [
        "#@title varying update rates\n",
        "async_ca = get_model('🦎', fire_rate=0.5)\n",
        "sync_ca = get_model('🦎', fire_rate=1.0)\n",
        "x = np.zeros([3, 2, 56, 56, CHANNEL_N], np.float32)\n",
        "x[:, :, 28, 28, 3:] = 1.0\n",
        "fn = 'update_rates.mp4'\n",
        "with VideoWriter(fn) as vid:\n",
        "  for i in tqdm.trange(3000):\n",
        "    for xk, rate in zip(x, [1, 5, 10]):\n",
        "      if i%rate == 0:\n",
        "        xk[:1] = async_ca(xk[:1], fire_rate=rate/10.0)[0]\n",
        "        xk[1:] = sync_ca(xk[1:], fire_rate=rate/10.0)[0]\n",
        "    if i%10 == 0:\n",
        "      vis = np.hstack(map(np.vstack, to_rgb(x)))\n",
        "      vis = zoom(vis, 2)\n",
        "      vid.add(vis)\n",
        "mvp.ipython_display(fn, loop=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "VScCKHo-Vkfe"
      },
      "outputs": [],
      "source": [
        "#@title compare_sync_async\n",
        "emj = '🦎🐠🦋🥨🕸'\n",
        "async_models = [get_model(ch, fire_rate=0.5) for ch in emj]\n",
        "sync_models = [get_model(ch, fire_rate=1.0) for ch in emj]\n",
        "frame_n = 10\n",
        "x = np.zeros([2, len(emj), frame_n, 56, 56, CHANNEL_N], np.float32)\n",
        "x[..., 28, 28, 3:] = 1.0\n",
        "for i in tqdm.trange(500):\n",
        "  for ca, xk in zip(async_models, x[0]):\n",
        "    xk[:] = ca(xk, fire_rate=0.5)\n",
        "  for ca, xk in zip(sync_models, x[1]):\n",
        "    xk[:] = ca(xk, fire_rate=0.5)\n",
        "\n",
        "fn = 'compare_sync_async.mp4'\n",
        "with VideoWriter(fn, 2.0) as vid:\n",
        "  for i in range(frame_n):\n",
        "    vis = np.vstack(map(np.hstack, to_rgb(x[:,:,i])))\n",
        "    vid.add(zoom(vis, 2))\n",
        "mvp.ipython_display(fn, loop=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "isJkBvnmzlT0"
      },
      "outputs": [],
      "source": [
        "#@title continuous time\n",
        "emoji = '🦎'\n",
        "target = load_emoji(emoji)\n",
        "target = np.pad(target, [(8, 8), (8, 8), (0, 0)])\n",
        "step_sizes = [0.1, 0.2, 0.5, 1.0]\n",
        "train_fire_rates = [0.5, 1.0]\n",
        "t_max = 300.0\n",
        "logs = {}\n",
        "for train_fire_rate in train_fire_rates:\n",
        "  ca = get_model(emoji, fire_rate=train_fire_rate)\n",
        "  for step in step_sizes:\n",
        "    loss_log = []\n",
        "    step_n = int(t_max/step)\n",
        "    x = np.zeros([1, 56, 56, CHANNEL_N], np.float32)\n",
        "    x[..., 28, 28, 3:] = 1.0\n",
        "    for i in range(step_n):\n",
        "      loss = tf.reduce_mean(tf.square(to_rgba(x)-target)).numpy()\n",
        "      loss_log.append(loss)\n",
        "      x = ca(x, fire_rate=1.0, step_size=step)\n",
        "    imshow(to_rgb(x)[0])\n",
        "    print('train_fire_rate:', train_fire_rate,\n",
        "          'step:', step, 'step_n:', step_n, 'loss:', loss)\n",
        "    logs[train_fire_rate, step] = loss_log\n",
        "\n",
        "with pl.style.context('bmh'):\n",
        "  fig, axs = pl.subplots(1, 2, sharey=True, figsize=(10, 4))\n",
        "  for ax, train_fire_rate in zip(axs, train_fire_rates):\n",
        "    for step in step_sizes:\n",
        "      log = logs[train_fire_rate, step]\n",
        "      t = np.arange(len(log))*step\n",
        "      style = ('', '--')[step == 1.0]\n",
        "      ax.plot(t, log, style, label='$\\lambda = %.1f$'%step)\n",
        "      name = ('asynchronous', 'synchronous')[train_fire_rate == 1.0]\n",
        "      ax.set_title('\"%s\" model\\n(train_fire_rate = %.1f)'%(name, train_fire_rate))\n",
        "      ax.set_xlabel('time')\n",
        "      ax.set_ylabel('loss')\n",
        "  pl.legend(bbox_to_anchor=(1.30, 1.03))\n",
        "  pl.yscale('log')\n",
        "  pl.tight_layout()\n",
        "  pl.savefig('sync_async_plot.svg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6hpkGx0MWhR-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ln -s \"/content/drive/My Drive/selforg/ca_growth/figures\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9M-oDuhea7bR"
      },
      "source": [
        "# Demo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "awtBdVu0yHQ8"
      },
      "outputs": [],
      "source": [
        "HTML('''\n",
        "\u003cstyle\u003e\n",
        "  #knob {\n",
        "     transform: rotate(-30deg);\n",
        "     width: 50px;\n",
        "     height: 50px;\n",
        "     font-size: 40px;\n",
        "     text-align: center;\n",
        "     user-select: none;\n",
        "  }\n",
        "\u003c/style\u003e\n",
        "\u003cp id='knob';\", style=\"transform: rotate(-30deg);\"\u003e➤\u003c/p\u003e\n",
        "\u003cscript\u003e\n",
        "  const knob = document.getElementById(\"knob\");\n",
        "  let ang = 0;\n",
        "  setInterval(()=\u003e{\n",
        "    knob.style.transform = `rotate(${ang}deg)`;\n",
        "    ang += 1.0;\n",
        "  }, 10);\n",
        "\u003c/script\u003e\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "D7ypa-b7_fTn"
      },
      "outputs": [],
      "source": [
        "#@title tfjs demo {run:\"auto\"}\n",
        "#from colabtools import interactive_forms\n",
        "import IPython.display\n",
        "#from IPython.display import display\n",
        "\n",
        "emoji = \"\\uD83D\\uDE00 1F600\"  #@param ['😀 1F600', '💥 1F4A5', '👁 1F441', '🦎 1F98E', '🐠 1F420', '🦋 1F98B', '🐞 1F41E', '🕸 1F578', '🥨 1F968', '🎄 1F384']\n",
        "model_type = '3 regenerating'  #@param ['1 naive', '2 persistent', '3 regenerating']\n",
        "\n",
        "code = emoji.split(' ')[1]\n",
        "emoji = chr(int(code, 16))\n",
        "experiment_i = int(model_type.split()[0])-1\n",
        "use_pool = (0, 1, 1)[experiment_i]\n",
        "damage_n = (0, 0, 3)[experiment_i]\n",
        "model_str = get_model(emoji, use_pool=use_pool, damage_n=damage_n, output='json')\n",
        "\n",
        "data_js = '''\n",
        "  window.GRAPH_URL = URL.createObjectURL(new Blob([`%s`], {type: 'application/json'}));\n",
        "'''%(model_str)\n",
        "\n",
        "display(IPython.display.Javascript(data_js))\n",
        "\n",
        "\n",
        "IPython.display.HTML('''\n",
        "\u003cscript src=\"https://unpkg.com/@tensorflow/tfjs-core@latest/dist/tf-core.js\"\u003e\u003c/script\u003e\n",
        "\u003cscript src=\"https://unpkg.com/@tensorflow/tfjs-layers@latest/dist/tf-layers.js\"\u003e\u003c/script\u003e\n",
        "\u003cscript src=\"https://unpkg.com/@tensorflow/tfjs-converter@latest/dist/tf-converter.js\"\u003e\u003c/script\u003e\n",
        "\u003cscript src=\"https://unpkg.com/@tensorflow/tfjs-backend-wasm@latest/dist/tf-backend-wasm.js\"\u003e\u003c/script\u003e\n",
        "\n",
        "\u003ccanvas id='canvas' style=\"border: 1px solid black; image-rendering: pixelated;\"\u003e\u003c/canvas\u003e\n",
        "\n",
        "\u003cscript\u003e\n",
        "  \"use strict\";\n",
        "  \n",
        "  const sleep = (ms)=\u003enew Promise(resolve =\u003e setTimeout(resolve, ms));\n",
        "  \n",
        "  const parseConsts = model_graph=\u003e{\n",
        "    const dtypes = {'DT_INT32':['int32', 'intVal', Int32Array],\n",
        "                    'DT_FLOAT':['float32', 'floatVal', Float32Array]};\n",
        "    \n",
        "    const consts = {};\n",
        "    model_graph.modelTopology.node.filter(n=\u003en.op=='Const').forEach((node=\u003e{\n",
        "      const v = node.attr.value.tensor;\n",
        "      const [dtype, field, arrayType] = dtypes[v.dtype];\n",
        "      if (!v.tensorShape.dim) {\n",
        "        consts[node.name] = [tf.scalar(v[field][0], dtype)];\n",
        "      } else {\n",
        "        const shape = v.tensorShape.dim.map(d=\u003eparseInt(d.size));\n",
        "        let arr;\n",
        "        if (v.tensorContent) {\n",
        "          const data = atob(v.tensorContent);\n",
        "          const buf = new Uint8Array(data.length);\n",
        "          for (var i=0; i\u003cdata.length; ++i) {\n",
        "            buf[i] = data.charCodeAt(i);\n",
        "          }\n",
        "          arr = new arrayType(buf.buffer);\n",
        "        } else {\n",
        "          const size = shape.reduce((a, b)=\u003ea*b);\n",
        "          arr = new arrayType(size);\n",
        "          arr.fill(v[field][0]);\n",
        "        }\n",
        "        consts[node.name] = [tf.tensor(arr, shape, dtype)];\n",
        "      }\n",
        "    }));\n",
        "    return consts;\n",
        "  }\n",
        "  \n",
        "  const run = async ()=\u003e{\n",
        "    const r = await fetch(GRAPH_URL);\n",
        "    const consts = parseConsts(await r.json());\n",
        "    \n",
        "    const model = await tf.loadGraphModel(GRAPH_URL);\n",
        "    Object.assign(model.weights, consts);\n",
        "    \n",
        "    let seed = new Array(16).fill(0).map((x, i)=\u003ei\u003c3?0:1);\n",
        "    seed = tf.tensor(seed, [1, 1, 1, 16]);\n",
        "    \n",
        "    const D = 96;\n",
        "    const initState = tf.tidy(()=\u003e{\n",
        "      const D2 = D/2;\n",
        "      const a = seed.pad([[0, 0], [D2-1, D2], [D2-1, D2], [0,0]]);\n",
        "      return a;\n",
        "    });\n",
        "    \n",
        "    const state = tf.variable(initState);\n",
        "    const [_, h, w, ch] = state.shape;\n",
        "    \n",
        "    const damage = (x, y, r)=\u003e{\n",
        "      tf.tidy(()=\u003e{\n",
        "        const rx = tf.range(0, w).sub(x).div(r).square().expandDims(0);\n",
        "        const ry = tf.range(0, h).sub(y).div(r).square().expandDims(1);\n",
        "        const mask = rx.add(ry).greater(1.0).expandDims(2);\n",
        "        state.assign(state.mul(mask));\n",
        "      });\n",
        "    }\n",
        "    \n",
        "    const plantSeed = (x, y)=\u003e{\n",
        "      const x2 = w-x-seed.shape[2];\n",
        "      const y2 = h-y-seed.shape[1];\n",
        "      if (x\u003c0 || x2\u003c0 || y2\u003c0 || y2\u003c0)\n",
        "        return;\n",
        "      tf.tidy(()=\u003e{\n",
        "        const a = seed.pad([[0, 0], [y, y2], [x, x2], [0,0]]);\n",
        "        state.assign(state.add(a));\n",
        "      });\n",
        "    }\n",
        "    \n",
        "    const scale = 4;\n",
        "    \n",
        "    const canvas = document.getElementById('canvas');\n",
        "    const ctx = canvas.getContext('2d');\n",
        "    canvas.width = w;\n",
        "    canvas.height = h;\n",
        "    canvas.style.width = `${w*scale}px`;\n",
        "    canvas.style.height = `${h*scale}px`;\n",
        "    \n",
        "    canvas.onmousedown = e=\u003e{\n",
        "      const x = Math.floor(e.clientX/scale);\n",
        "        const y = Math.floor(e.clientY/scale);\n",
        "        if (e.buttons == 1) {\n",
        "          if (e.shiftKey) {\n",
        "            plantSeed(x, y);  \n",
        "          } else {\n",
        "            damage(x, y, 8);\n",
        "          }\n",
        "        }\n",
        "    }\n",
        "    canvas.onmousemove = e=\u003e{\n",
        "      const x = Math.floor(e.clientX/scale);\n",
        "      const y = Math.floor(e.clientY/scale);\n",
        "      if (e.buttons == 1 \u0026\u0026 !e.shiftKey) {\n",
        "        damage(x, y, 8);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    for (let i=0;; ++i) {\n",
        "      if (i%2==0) {\n",
        "        const imageData = tf.tidy(()=\u003e{\n",
        "          const rgba = state.slice([0, 0, 0, 0], [-1, -1, -1, 4]);\n",
        "          const a = state.slice([0, 0, 0, 3], [-1, -1, -1, 1]);\n",
        "          const img = tf.tensor(1.0).sub(a).add(rgba).mul(255);\n",
        "          //const scaledImg = tf.image.resizeNearestNeighbor(img, [h*scale, w*scale]);\n",
        "          const rgbaBytes = new Uint8ClampedArray(img.dataSync());\n",
        "          return new ImageData(rgbaBytes, w, h);\n",
        "        });\n",
        "        ctx.putImageData(imageData, 0, 0);\n",
        "        // const image = await createImageBitmap(\n",
        "        //   imageData,\n",
        "        //   {resizeWidth: w*scale, resizeHeight: h*scale, resizeQuality: 'pixelated'});\n",
        "//        ctx.drawImage(image, 0, 0);\n",
        "        await sleep(1);\n",
        "      }\n",
        "      tf.tidy(()=\u003e{\n",
        "        state.assign(model.execute(\n",
        "            {x:state, fire_rate:tf.tensor(0.5),\n",
        "            angle:tf.tensor(0.0), step_size:tf.tensor(1.0)}, ['Identity']));\n",
        "      });\n",
        "    }\n",
        "  }\n",
        "  //tf.setBackend('wasm').then(run);\n",
        "  run();\n",
        "  \n",
        "\u003c/script\u003e\n",
        "\n",
        "\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_M1zjIg1_7ZA"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('json_models.zip', 'w') as zf:\n",
        "  for e in EMOJI:\n",
        "    s = get_model(e, output='json')\n",
        "    zf.writestr(e+'.json', s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s76CHdn1Iah7"
      },
      "source": [
        "## WebGL demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "POma99rMIfV4"
      },
      "outputs": [],
      "source": [
        "def pack_layer(weight, bias, outputType=np.uint8):\n",
        "  in_ch, out_ch = weight.shape\n",
        "  assert (in_ch%4==0) and (out_ch%4==0) and (bias.shape==(out_ch,))\n",
        "  weight_scale, bias_scale = 1.0, 1.0\n",
        "  if outputType == np.uint8:\n",
        "    weight_scale = 2.0*np.abs(weight).max()\n",
        "    bias_scale = 2.0*np.abs(bias).max()\n",
        "    weight = np.round((weight/weight_scale+0.5)*255)\n",
        "    bias = np.round((bias/bias_scale+0.5)*255)\n",
        "  packed = np.vstack([weight, bias[None,...]])\n",
        "  packed = packed.reshape(in_ch+1, out_ch//4, 4)\n",
        "  packed = outputType(packed)\n",
        "  packed_b64 = base64.b64encode(packed.tobytes()).decode('ascii')\n",
        "  return {'data_b64': packed_b64, 'in_ch': in_ch, 'out_ch': out_ch,\n",
        "          'weight_scale': weight_scale, 'bias_scale': bias_scale,\n",
        "          'type': outputType.__name__}\n",
        "\n",
        "def export_ca_to_webgl_demo(ca, outputType=np.uint8):\n",
        "  # reorder the first layer inputs to meet webgl demo perception layout\n",
        "  chn = ca.channel_n\n",
        "  w1 = ca.weights[0][0, 0].numpy()\n",
        "  w1 = w1.reshape(chn, 3, -1).transpose(1, 0, 2).reshape(3*chn, -1)\n",
        "  layers = [\n",
        "      pack_layer(w1, ca.weights[1].numpy(), outputType),\n",
        "      pack_layer(ca.weights[2][0, 0].numpy(), ca.weights[3].numpy(), outputType)\n",
        "  ]\n",
        "  return json.dumps(layers)\n",
        "\n",
        "with zipfile.ZipFile('webgl_models8.zip', 'w') as zf:\n",
        "  for e in EMOJI:\n",
        "    zf.writestr('ex1_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=0, damage_n=0)))\n",
        "    run = 1 if e in '😀🕸' else 0  # select runs that happens to quantize better\n",
        "    zf.writestr('ex2_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=1, damage_n=0, run=run)))\n",
        "    run = 1 if e in '🦎' else 0    # select runs that happens to quantize better\n",
        "    zf.writestr('ex3_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=1, damage_n=3, run=run)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pxQntHFx0hui"
      },
      "outputs": [],
      "source": [
        "print(EMOJI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_-P_GcTcGFeB"
      },
      "outputs": [],
      "source": [
        "!zip planarian.zip train_log/8000*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "growing_ca clear output",
      "provenance": [
        {
          "file_id": "11mx7GFlad93yvXfXabU7YHTS_Paphmtm",
          "timestamp": 1580227535188
        },
        {
          "file_id": "/piper/depot/google3/third_party/py/self_organising_systems/notebooks/growing_ca.ipynb?workspaceId=etr:thirdp::citc",
          "timestamp": 1580227474085
        },
        {
          "file_id": "1oqVn8ReE7vp77nQLSWAY3v3O_0y-n87Q",
          "timestamp": 1580227004370
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
